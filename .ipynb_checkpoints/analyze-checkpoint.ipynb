{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker BRATS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import os\n",
    "import seaborn as sb\n",
    "import math\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from nltk import agreement\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the variables and environment\n",
    "met = 'wt'\n",
    "# stupid switch for dumb experiments to make data pretty\n",
    "stupid = False\n",
    "\n",
    "#set baseline variables for export and stuff\n",
    "res = 400 # dpi value for image export\n",
    "form = 'png' #image format for matplotlib exports\n",
    "filename = met + '_dice_scores.csv'\n",
    "#rename colums to their 3 character IDs\n",
    "candidates = {\n",
    "        'aju' : 'tumor_istb_aj_class.nii',\n",
    "        'aca' : 'data_data_prediction.nii.gz',\n",
    "        'kch' : 'tumor_qtimlab_class.nii.gz',\n",
    "        'ekr' : 'tumor_00000000_class.nii.gz',\n",
    "        'aka' : 'tumor_kamleshp_class.nii.gz',\n",
    "        'mag' : 'tumor_magnrbm_class.nii',\n",
    "        'sse' : 'tumor_saras_tb_class.nii.gz',\n",
    "        'rsa': 'tumor_gevaertlab_class.nii',\n",
    "        'gwa' : 'brats_dc_brats2016_test_klhd_pat101_3.nii.gz',\n",
    "        'ise' : 'tumor_brats2017_isensee_class.nii.gz',\n",
    "        'mav' : 'majvote_fusion.nii.gz',\n",
    "        'sim' : 'simple_fusion.nii.gz',\n",
    "        'sim2': 'simple2_fusion.nii.gz',\n",
    "        'none' : 'default'\n",
    "    }\n",
    "\n",
    "sseRep = {\n",
    "    'brats2016_test_cbica_patAMQ_362' : 0,\n",
    "    'brats2016_test_tcia_pat457_0079' : 0,\n",
    "    'brats2016_test_cbica_patAOQ1_1' : 0\n",
    "}\n",
    "#invert the indices to assign the proper labels\n",
    "inv_cand = {v: k for k, v in candidates.items()}\n",
    "\n",
    "irrScores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "data = pandas.read_csv(filename)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data\n",
    "def preprocessor(data, met):\n",
    "    # remove every 2nd row (unnecessary column heads)\n",
    "    clean = data.replace({'tumor_saras_tb_class.nii.gz' : sseRep})\n",
    "    clean = clean.iloc[::2]\n",
    "    # remove patient name column\n",
    "    # clean = clean.drop('patient', axis=1)\n",
    "    # rename columns to 3 digit ID\n",
    "    clean = clean.rename(inv_cand, axis=1)\n",
    "    # store csv\n",
    "    #clean.reset_index(inplace=True)\n",
    "    #print(clean)\n",
    "    clean.to_csv(met+'_clean.csv')\n",
    "    # read a clean copy of the preprocessed csv again\n",
    "    data = pandas.read_csv('fixed_data/'+met+'_clean.csv')\n",
    "    # remove wrong row indices\n",
    "    data = data.drop('Unnamed: 0', axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessor(data, met)\n",
    "# read a clean copy of the preprocessed csv again\n",
    "# data = pandas.read_csv(met+'_clean.csv')\n",
    "# remove wrong row indices\n",
    "# data = data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter Rater Reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRR function using the Cohen Kappa Score \n",
    "# https://en.wikipedia.org/wiki/Cohen%27s_kappa\n",
    "# create empty dataframe for correlation indices\n",
    "\n",
    "def irr(data, res, base=5):\n",
    "    \"\"\" Data is the Dataframe with the initial data\n",
    "    irr is an empty DataFrame with matching columns and indices\n",
    "    (nxn matrix of n columns) for the resulting scores\n",
    "    base is the class interval size (default: 5)\n",
    "    \"\"\"\n",
    "    for r1 in data:\n",
    "        if r1 != 'patient':\n",
    "            # convert continuous values to integer classes\n",
    "            rater1 = (data[r1].round(decimals=2)*100).tolist()\n",
    "            rater1 = list(map(int, rater1))\n",
    "            rater1 = [base*math.floor(x/base) for x in rater1]\n",
    "        for r2 in data:\n",
    "            if r2 != 'patient':\n",
    "                rater2 = (data[r2].round(decimals=2)*100).tolist()\n",
    "                rater2 = list(map(int, rater2))\n",
    "                rater2 = [base*math.floor(x/base) for x in rater2]\n",
    "                # calculate the cohen kappa score \n",
    "                res.loc[r1, r2] = cohen_kappa_score(rater1, rater2)\n",
    "    # minimal postprocessing before returning\n",
    "    res = res.astype(float).round(decimals=2)\n",
    "    return res\n",
    "\n",
    "\n",
    "rows = list(candidates.keys())\n",
    "res = pandas.DataFrame(data=None, index=rows, columns=rows)\n",
    "res.drop(labels=['none', 'sim2'], axis=0, inplace=True)\n",
    "res.drop(labels=['none', 'sim2'], axis=1, inplace=True)\n",
    "res = irr(data, res, 5)\n",
    "export = res.to_latex()\n",
    "irrScores[met] = res\n",
    "with open(met + '_irr.txt', 'w') as f: \n",
    "    f.write(export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre- and Postoperative Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preop = data[data['patient'].str.endswith('1', na='nan')]\n",
    "postop = data.mask(data['patient'].str.endswith('1', na='nan'))\n",
    "postop = postop.dropna(axis=0)\n",
    "postop.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRR for Pre- and Postoperative cases:\n",
    "# create empty dataframe for correlation indices\n",
    "res2 = pandas.DataFrame(data=None, index=rows, columns=rows)\n",
    "temp = irr(preop, res2, base=5)\n",
    "temp = temp.astype(float).round(decimals=2)\n",
    "temp.drop(labels=['none', 'sim2', 'patient'], axis=0, inplace=True)\n",
    "temp.drop(labels=['none', 'sim2'], axis=1, inplace=True)\n",
    "print(temp)\n",
    "export = temp.to_latex()\n",
    "irrScores['preop'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = pandas.DataFrame(data=None, index=rows, columns=rows)\n",
    "temp = irr(postop, res3, base=5)\n",
    "temp = temp.astype(float).round(decimals=2)\n",
    "temp.drop(labels=['none', 'sim2', 'patient'], axis=0, inplace=True)\n",
    "temp.drop(labels=['none', 'sim2'], axis=1, inplace=True)\n",
    "print(temp)\n",
    "export = temp.to_latex()\n",
    "irrScores['postop'] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump Data to File \n",
    "And reload for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all data to a pickle file\n",
    "with open('irr.pkl', 'wb') as f:\n",
    "        pickle.dump(irrScores, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data again\n",
    "with open('irr.pkl', 'rb') as f:\n",
    "        scoresReloaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test it\n",
    "print(scoresReloaded['wt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['brats2016_test_2013_pat0136_1', 'brats2016_test_2013_pat0137_1', 'brats2016_test_2013_patx116_1', 'brats2016_test_cbica_patAAA_1'])\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/christoph/Documents/Code/project-kraken/results.pkl', 'rb') as f:\n",
    "        giantScores = pickle.load(f)\n",
    "print(giantScores.keys())\n",
    "giantScores['brats2016_test_2013_pat0136_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preop and Postop Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison of the mean values for pre- and post-operative scans\n",
    "comp = pandas.concat([preop.mean(), postop.mean(), (postop.mean()- preop.mean()), preop.std(), postop.std()], axis=1, sort=True)\n",
    "newname = {0:'Preop Mean', \n",
    "           1:'Postop Mean',\n",
    "           2:'Difference',\n",
    "           3: 'Preop STDEV',\n",
    "           4: 'Postop STDEV'\n",
    "          }\n",
    "comp = comp.rename(columns=newname)\n",
    "print('Comparison for region ' + met + ': \\n', comp)\n",
    "print('\\nMean difference: ' + str(comp['Difference'].mean()))\n",
    "print('\\nMean difference stdev: ' + str(comp['Difference'].std()))\n",
    "comp = comp.round(decimals=3)*100\n",
    "tex = comp.to_latex()\n",
    "with open('textable-'+met+'.txt', 'w') as f: \n",
    "    f.write(tex)\n",
    "prepostplot = sb.boxplot(data=comp['Difference'], width=0.5, palette='spring')\n",
    "# assemble comprehensive table\n",
    "if met == 'wt':\n",
    "    wtcomp = comp.mean()\n",
    "if met == 'tc':\n",
    "    tccomp = comp.mean()\n",
    "if met == 'at':\n",
    "    atcomp = comp.mean()\n",
    "    \n",
    "compressed = pandas.concat([wtcomp, tccomp, atcomp], axis=1, sort=False)\n",
    "compressed = compressed.rename(columns={0: 'Whole Tumor', 1:'Tumor Core', 2:'Active Tumor'})\n",
    "compressed = compressed.round(decimals=1)\n",
    "print(compressed)\n",
    "tex2 = compressed.to_latex()\n",
    "with open('textable-complete.txt', 'w') as f: \n",
    "    f.write(tex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stupid:\n",
    "    beauty = data[data.mav > 0.3]\n",
    "    data = beauty\n",
    "beauty.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the indices by their mean value and reorder the data frame for descending plotting\n",
    "m = data.mean()\n",
    "m_sorted = m.sort_values(ascending=False)\n",
    "print('Mean values sorted:')\n",
    "pprint(m_sorted)\n",
    "print('\\nMedian sorted:')\n",
    "pprint(data.median().sort_values(ascending=False))\n",
    "print('\\nStandard deviation sorted:')\n",
    "pprint(data.std().sort_values(ascending=True))\n",
    "indices = m_sorted.keys()\n",
    "# order dataframe by mean\n",
    "indices = indices.tolist()\n",
    "wt_ordered = data[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all metrics to a table \n",
    "metrics = pandas.concat([m_sorted, data.median(), data.std()], axis=1, sort=True)\n",
    "newname = {0:'Mean', \n",
    "           1:'Median',\n",
    "           2:'Std-Dev'}\n",
    "metrics = metrics.rename(columns=newname)\n",
    "# round the values - who needs 8 decimals for such scores?!\n",
    "metrics = metrics.round(decimals=3)\n",
    "print(metrics)\n",
    "metrics.to_csv('tables/'+met+'_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "bplot = sb.boxplot(data=wt_ordered, \n",
    "                 width=0.5,\n",
    "                 palette=\"colorblind\")\n",
    "#bplot.axes.set_title('DICE Scores for whole tumor', fontsize=16)\n",
    "bplot.set_xlabel('Algorithms', fontsize=8)\n",
    "bplot.set_ylabel('Dice score', fontsize=8)\n",
    "#plot a horizontal line at the max mean location\n",
    "bplot.hlines(np.max(data.median()), -100, 1000, colors='r')\n",
    "#save the plot\n",
    "bplot.figure.savefig('plots/'+met+'_fullplot_thresh3.png', format=form, dpi=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.split(wt_ordered, [5], axis=1)\n",
    "bplot1 = sb.boxplot(data=results[0], \n",
    "                 width=0.5,\n",
    "                 palette=\"colorblind\")\n",
    "#bplot.axes.set_title('DICE Scores for whole tumor', fontsize=16)\n",
    "bplot1.set_xlabel('Algorithms', fontsize=14)\n",
    "bplot1.set_ylabel('Dice score', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bplot2 = sb.boxplot(data=results[1], \n",
    "                 width=0.5,\n",
    "                 palette=\"colorblind\")\n",
    "#bplot.axes.set_title('DICE Scores for whole tumor', fontsize=16)\n",
    "bplot2.set_xlabel('Algorithms', fontsize=14)\n",
    "bplot2.set_ylabel('Dice score', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all of it\n",
    "#bplot1.figure.savefig(met+'_boxplot1.png', format=form, dpi=res)\n",
    "#bplot2.figure.savefig(met+'_boxplot2.png', format=form, dpi=res)\n",
    "cl.savefig('clustermap.png', format=form, dpi=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cl = sb.clustermap(wt_ordered, method='complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compound table for DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv('wt_dice_scores.csv')\n",
    "wt_scores = preprocessor(data, 'whole')\n",
    "tc_scores = preprocessor(pandas.read_csv('tc_dice_scores.csv'), 'core')\n",
    "at_scores = preprocessor(pandas.read_csv('at_dice_scores.csv'), 'active')\n",
    "wt_scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_m = wt_scores.median()\n",
    "tc_m = tc_scores.median()\n",
    "at_m = at_scores.median()\n",
    "bobby = pandas.concat([wt_m, tc_m, at_m], axis=1, sort=True)\n",
    "newkidz = {\n",
    "    0 : 'WT',\n",
    "    1 : 'TC',\n",
    "    2 : 'AT'\n",
    "}\n",
    "bobby = bobby.rename(columns=newkidz)\n",
    "bobby = bobby.round(decimals=3)*100\n",
    "bobby.to_csv('tables/concisedice.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specificity and Sensitivity Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "wt_spec = preprocessor(pandas.read_csv('specificity/wt_scores.csv'), 'wt-spec')\n",
    "tc_spec = preprocessor(pandas.read_csv('specificity/tc_scores.csv'), 'tc-spec')\n",
    "at_spec = preprocessor(pandas.read_csv('specificity/at_scores.csv'), 'at-spec')\n",
    "\n",
    "wt_sens = preprocessor(pandas.read_csv('sensitivity/wt_scores.csv'), 'wt-sens')\n",
    "tc_sens = preprocessor(pandas.read_csv('sensitivity/tc_scores.csv'), 'tc-sens')\n",
    "at_sens = preprocessor(pandas.read_csv('sensitivity/at_scores.csv'), 'at-sens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_spec.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_sens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Series for mean of specificity and sensitivity\n",
    "wtsp_m = wt_spec.mean().round(decimals=3)\n",
    "wtse_m = wt_sens.mean().round(decimals=3)\n",
    "wtse_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble Series to a single dataframe and rename the columns\n",
    "wt_plt = pandas.concat([wtsp_m, wtse_m], axis=1, sort=True)\n",
    "wt_plt = wt_plt.rename({0: 'Specificity', 1:'Sensitivity'}, axis=1)\n",
    "# define some colors for the plots\n",
    "colors = ['red','green','blue', 'aqua','gold','fuchsia', 'indigo','lavender','orange', 'sienna','teal','plum']\n",
    "# plot sensitivity vs specificity \n",
    "ax = wt_plt.plot.scatter(x=0, y=1, c=colors, marker='s')\n",
    "for i, txt in enumerate(wt_plt.index):\n",
    "    ax.annotate(txt, (wt_plt.Specificity.iat[i],wt_plt.Sensitivity.iat[i]))\n",
    "ax.grid(True)\n",
    "ax.set_title('Whole Tumor Specificity vs Sensitivity')\n",
    "ax.figure.savefig('wt_sesp.png', format=form, dpi=res)\n",
    "#ax.annotate('aca', wt_plt[0][0], wt_plt[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcsp_m = tc_spec.mean().round(decimals=3)\n",
    "tcse_m = tc_sens.mean().round(decimals=3)\n",
    "tc_plt = pandas.concat([tcsp_m, tcse_m], axis=1, sort=True)\n",
    "tc_plt = tc_plt.rename({0: 'Specificity', 1:'Sensitivity'}, axis=1)\n",
    "colors = ['red','green','blue', 'aqua','gold','fuchsia', 'indigo','lavender','orange', 'sienna','teal','plum']\n",
    "ax = tc_plt.plot.scatter(x=0, y=1, c=colors, marker='s')\n",
    "for i, txt in enumerate(tc_plt.index):\n",
    "    ax.annotate(txt, (tc_plt.Specificity.iat[i],tc_plt.Sensitivity.iat[i]))\n",
    "ax.grid(True)\n",
    "ax.set_title('Tumor Core Specificity vs Sensitivity')\n",
    "ax.figure.savefig('tc_sesp.png', format=form, dpi=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atsp_m = at_spec.mean().round(decimals=3)\n",
    "atse_m = at_sens.mean().round(decimals=3)\n",
    "at_plt = pandas.concat([atsp_m, atse_m], axis=1, sort=True)\n",
    "at_plt = at_plt.rename({0: 'Specificity', 1:'Sensitivity'}, axis=1)\n",
    "colors = ['red','green','blue', 'aqua','gold','fuchsia', 'indigo','lavender','orange', 'sienna','teal','plum']\n",
    "ax = at_plt.plot.scatter(x=0, y=1, c=colors, marker='s')\n",
    "for i, txt in enumerate(at_plt.index):\n",
    "    ax.annotate(txt, (at_plt.Specificity.iat[i],at_plt.Sensitivity.iat[i]))\n",
    "ax.grid(True)\n",
    "ax.set_title('Active Tumor Specificity vs Sensitivity')\n",
    "ax.figure.savefig('at_sesp.png', format=form, dpi=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#once again but with MEDIAN \n",
    "atsp_m = at_spec.median().round(decimals=3)\n",
    "atse_m = at_sens.median().round(decimals=3)\n",
    "at_plt = pandas.concat([atsp_m, atse_m], axis=1, sort=True)\n",
    "at_plt = at_plt.rename({0: 'Specificity', 1:'Sensitivity'}, axis=1)\n",
    "colors = ['red','green','blue', 'aqua','gold','fuchsia', 'indigo','lavender','orange', 'sienna','teal','plum']\n",
    "ax = at_plt.plot.scatter(x=0, y=1, c=colors, marker='s')\n",
    "for i, txt in enumerate(at_plt.index):\n",
    "    ax.annotate(txt, (at_plt.Specificity.iat[i],at_plt.Sensitivity.iat[i]))\n",
    "ax.grid(True)\n",
    "ax.set_title('Active Tumor Specificity vs Sensitivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens = at_plt.plot(y='Sensitivity', kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
